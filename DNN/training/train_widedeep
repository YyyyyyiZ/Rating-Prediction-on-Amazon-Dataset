import pandas as pd  
import numpy as np  
import torch  
import torch.nn as nn  
import torch.optim as optim  
from torch.utils.data import Dataset, DataLoader  
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_curve, auc, classification_report  
import matplotlib.pyplot as plt
from preprocessing import prep_amazon
from models import WideDeep1, WideDeep2

torch.manual_seed(42) 

def evaluate_model_widedeep(model, X_wide, X_deep, y):  
    model.eval()  
    with torch.no_grad():  
        wide_input = torch.tensor(X_wide, dtype=torch.float32)  
        deep_input = torch.tensor(X_deep, dtype=torch.float32)  
        target = torch.tensor(y, dtype=torch.float32).view(-1, 1)  

        outputs = model(wide_input, deep_input)  
        predictions = outputs.numpy()  

        rmse = np.sqrt(mean_squared_error(y, predictions)) 
        mse = mean_squared_error(y, predictions)  
        mae = mean_absolute_error(y, predictions)  
    
    return rmse, mse, mae 


def train_model_widedeep(model, X_wide, X_deep, y, X_test_wide, X_test_deep, y_test, epochs=200, lr=0.001):  
    model.train()  
    optimizer = optim.Adam(model.parameters(), lr=lr)  
    loss_fn = nn.MSELoss()  
    train_losses = []  
    train_rmses = []
    train_mses = []
    train_maes = []
    test_rmses = []
    test_mses = []
    test_maes = []

    for epoch in range(epochs):  
        optimizer.zero_grad()  
        
        wide_input = torch.tensor(X_wide, dtype=torch.float32)  
        deep_input = torch.tensor(X_deep, dtype=torch.float32)  
        target = torch.tensor(y, dtype=torch.float32).view(-1, 1)  

        outputs = model(wide_input, deep_input)  
        loss = loss_fn(outputs, target)  
        loss.backward()  
        optimizer.step()  

        train_losses.append(loss.item())  
        
        train_rmse, train_mse, train_mae = evaluate_model_widedeep(model, X_train_wide, X_train_deep, y_train)  
        test_rmse, test_mse, test_mae = evaluate_model_widedeep(model, X_test_wide, X_test_deep, y_test)  
        train_rmses.append(train_rmse)
        train_mses.append(train_mse)
        train_maes.append(train_mae)
        test_rmses.append(test_rmse)
        test_mses.append(test_mse)
        test_maes.append(test_mae)
        
        if (epoch+1) % 10 == 0:  
            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.6f}, train_rmse: {train_rmse:.6f}, test_rmse: {test_rmse:.6f}')  

    
    return train_losses,train_rmses,train_mses,train_maes,test_rmses,test_mses,test_maes

# 训练模型  
X_train_deep, X_test_deep, X_train_wide, X_test_wide, y_train, y_test=prep_amazon()
wide_input_dim = X_train_wide.shape[1]   
deep_input_dim = X_train_deep.shape[1]  
model1 = WideDeep1(wide_input_dim, deep_input_dim)

train_losses1,train_rmses1,train_mses1,train_maes1,test_rmses1,test_mses1,test_maes1 = train_model_widedeep(model1, X_train_wide, X_train_deep, y_train, X_test_wide, X_test_deep, y_test) 
